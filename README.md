# ğŸ¤– Adaptive Tutorial Agent

An AI-powered educational system that uses **Reinforcement Learning** to personalize the learning experience for each student.

## ï¿½ Project Overview

This system implements two RL agents that work together to create an adaptive tutorial experience:
- **Q-Learning Agent**: Adapts question difficulty based on student performance
- **Policy Gradient Agent**: Selects optimal content and teaching strategies

## ğŸ—ï¸ Architecture

### Backend (FastAPI + RL Agents)
- `main.py` - FastAPI server with WebSocket support
- `agents/q_learning_tutor.py` - Q-Learning agent for difficulty adaptation
- `agents/policy_gradient_tutor.py` - Policy Gradient agent for content selection
- `environment/tutorial_environment.py` - Tutorial environment simulation
- `agents/training_manager.py` - Multi-agent training coordination

### Frontend (React)
- Interactive tutorial interface
- Real-time learning analytics dashboard
- AI agent decision visualization

## ğŸš€ Quick Start

### Backend Setup
```bash
cd backend
pip install -r requirements.txt
python main.py
```

### Frontend Setup
```bash
cd frontend
npm install
npm start
```

### Access the Application
- Frontend: http://localhost:3000
- Backend API: http://localhost:8000
- API Docs: http://localhost:8000/docs

## ğŸ“Š Features

### ğŸ§  AI-Powered Adaptation
- **Dynamic Difficulty**: Q-Learning agent adjusts question difficulty in real-time
- **Content Selection**: Policy Gradient agent chooses optimal learning materials
- **Personalized Hints**: Context-aware hint generation
- **Performance Tracking**: Continuous learning analytics

### ğŸ“ Educational Features
- Multiple subjects (Math, Science, History, Literature)
- Various question types (Multiple Choice, Short Answer, Essay)
- Adaptive difficulty levels (Beginner, Intermediate, Advanced)
- Real-time feedback and hints

### ğŸ“ˆ Analytics Dashboard
- Student performance metrics
- AI agent decision insights
- Learning progress visualization
- Topic-specific performance tracking

## ğŸ§ª Training the Agents

### Using Google Colab (Recommended)
```python
# Upload training_manager.py and agent files to Colab
from training_manager import TrainingManager

manager = TrainingManager()
manager.train_agents(episodes=1000)
manager.save_models("trained_models/")
```

### Local Training
```bash
cd backend
python -c "from agents.training_manager import TrainingManager; TrainingManager().train_agents(1000)"
```

## ğŸ”§ Configuration

### Environment Settings
```python
# In tutorial_environment.py
TOPICS = ["Math", "Science", "History", "Literature"]
DIFFICULTY_LEVELS = ["beginner", "intermediate", "advanced"]
QUESTION_TYPES = ["multiple_choice", "short_answer", "essay"]
```

### Agent Parameters
```python
# Q-Learning Agent
learning_rate = 0.1
epsilon = 0.1
gamma = 0.95

# Policy Gradient Agent
learning_rate = 0.001
gamma = 0.99
```

## ğŸ“‹ API Endpoints

### WebSocket Connection
- `ws://localhost:8000/ws` - Real-time tutorial session

### REST API
- `GET /api/status` - System status and configuration
- `POST /api/reset` - Reset agent states
- `GET /api/stats` - Learning statistics

## ğŸ¯ Key RL Components

### State Representation
- Student performance metrics
- Question difficulty history
- Topic mastery levels
- Response time patterns

### Action Spaces
- **Q-Learning**: `[easier, harder, change_topic, hint, review, continue, assess]`
- **Policy Gradient**: `[concept_intro, practice, example, assessment, review]`

### Reward Functions
- Correct answers: +1.0
- Improved performance: +0.5
- Engagement maintenance: +0.3
- Optimal difficulty: +0.2

## ğŸ› ï¸ Technology Stack

- **Backend**: FastAPI, PyTorch, NumPy, WebSockets
- **Frontend**: React, CSS3, WebSocket API
- **ML**: Q-Learning, REINFORCE Policy Gradient
- **Training**: Google Colab compatible

## ğŸ“š Educational Impact

This system demonstrates how RL can revolutionize education by:
- Personalizing learning paths for individual students
- Adapting in real-time to student needs
- Optimizing engagement and learning efficiency
- Providing data-driven insights for educators

## ğŸ”® Future Enhancements

- Multi-modal learning (text, images, videos)
- Advanced NLP for automated question generation
- Collaborative learning environments
- Integration with existing LMS platforms

## ğŸ“„ License

This project is for educational purposes and demonstrates the application of Reinforcement Learning in adaptive education systems.
python demo.py
```

### ğŸ§  Step 2: Train Models in Google Colab (SIMPLIFIED!)
1. **Open Colab**: Go to [Google Colab](https://colab.research.google.com/)
2. **Upload Notebook**: Upload `colab/warehouse_rl_training.ipynb` directly to Colab
3. **Run Training**: Click "Runtime" â†’ "Run All" (takes ~30-60 minutes)
4. **Download Models**: After training, Colab will automatically create a zip file for download

**No need to upload entire folder to Google Drive!** The notebook is self-contained.

### ğŸš€ Step 3: Run with Trained Models
```bash
# Backend with trained models
python backend/main.py
# Server runs on http://localhost:8000
```

### ğŸ¨ Step 4: Frontend Visualization
```bash
cd frontend
npm install
npm start
# React app runs on http://localhost:3000
```

## Training Instructions

### Required Colab File
- **File**: `colab/warehouse_rl_training_new.ipynb` (OPTIMIZED VERSION âœ…)
- **Platform**: Google Colab (recommended for GPU acceleration)
- **Duration**: 30-60 minutes
- **Output**: Trained models + performance metrics

### Model Download & Setup
**âœ… MODELS ALREADY DEPLOYED!** The trained models from the optimized Colab session are now in `backend/models/`:

```
backend/models/
â”œâ”€â”€ final_q_learning.pkl            # Q-Learning navigator agents (TRAINED âœ…)
â”œâ”€â”€ final_policy_gradient_policy_agent_*.pth    # Task manager neural networks (TRAINED âœ…)
â”œâ”€â”€ final_policy_gradient_value_agent_*.pth     # Value networks (TRAINED âœ…)
â”œâ”€â”€ final_training_stats.json       # Complete training metrics
â”œâ”€â”€ training_progress.png           # Training visualization charts
â”œâ”€â”€ agent_comparison.png           # Q-Learning vs Policy Gradient comparison
â”œâ”€â”€ normalized_performance.png     # Performance metrics over time
â””â”€â”€ experiment_results_summary.json # Performance analysis
```

**Training Results Summary:**
- ğŸ¯ **Collision Rate**: 0.010 (âœ… Target <0.05 achieved)
- ğŸ“ˆ **Performance Improvement**: +58.4% over training
- ğŸ§  **Q-States Explored**: 609,461 unique states
- âš¡ **Training Duration**: 1.62 hours on Google Colab
- ğŸ† **Statistical Significance**: p < 0.05 (highly significant learning)

## Current System State
âœ… **Demo Working**: Complete system validation successful  
âœ… **Training Complete**: Optimized models trained and deployed  
âœ… **Production Ready**: Trained models loaded in backend/models/

## Project Structure
```
warehouse_rl_system/
â”œâ”€â”€ backend/                 # FastAPI server
â”‚   â”œâ”€â”€ environment/        # Grid world environment
â”‚   â”œâ”€â”€ agents/            # RL agent implementations
â”‚   â”œâ”€â”€ models/            # Model loading utilities
â”‚   â””â”€â”€ api/               # WebSocket & REST APIs
â”œâ”€â”€ frontend/              # React dashboard
â”œâ”€â”€ colab/                 # Training notebooks for Colab
â”œâ”€â”€ models/                # Trained model storage
â””â”€â”€ docs/                  # Documentation and results
```

## Requirements Met
- âœ… **Two RL Approaches**: Q-Learning + Policy Gradient
- âœ… **Multi-Agent System**: Coordinated warehouse robots
- âœ… **Agent Orchestration**: Dynamic task allocation
- âœ… **Real-time Learning**: Observable improvement over time
- âœ… **Performance Metrics**: Comprehensive evaluation
